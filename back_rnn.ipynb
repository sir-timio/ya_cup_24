{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_FOLDER = \"./YandexCup2024v2\"\n",
    "\n",
    "TRAIN_DATASET_PATH = os.path.join(ROOT_DATA_FOLDER, \"YaCupTrain\")\n",
    "TEST_DATASET_PATH = os.path.join(ROOT_DATA_FOLDER, \"YaCupTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all ids of a dataset\n",
    "\n",
    "def read_testcase_ids(dataset_path: str):\n",
    "    ids = [int(case_id) for case_id in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, case_id))]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = read_testcase_ids(TRAIN_DATASET_PATH)\n",
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = read_testcase_ids(TEST_DATASET_PATH)\n",
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFilePaths:\n",
    "    def __init__(self, testcase_path: str):\n",
    "        self.testcase_path = testcase_path\n",
    "        \n",
    "    def localization(self):\n",
    "        return os.path.join(self.testcase_path, 'localization.csv')\n",
    "    \n",
    "    def control(self):\n",
    "        return os.path.join(self.testcase_path, 'control.csv')\n",
    "    \n",
    "    def metadata(self):\n",
    "        return os.path.join(self.testcase_path, 'metadata.json')\n",
    "    \n",
    "    # exists only for test_dataset\n",
    "    def requested_stamps(self):\n",
    "        return os.path.join(self.testcase_path, 'requested_stamps.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def read_localization(localization_path: str):\n",
    "    return pd.read_csv(localization_path)\n",
    "\n",
    "def read_control(control_path):\n",
    "    return pd.read_csv(control_path)\n",
    "\n",
    "def read_metadata(metadata_path: str):\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def read_requested_stamps(requested_stamps_path: str):\n",
    "    return pd.read_csv(requested_stamps_path)\n",
    "    \n",
    "def read_testcase(dataset_path: str, testcase_id: str, is_test: bool = False):\n",
    "    testcase_path = os.path.join(dataset_path, str(testcase_id))\n",
    "    data_file_paths = DataFilePaths(testcase_path)\n",
    "    \n",
    "    testcase_data = {}\n",
    "    testcase_data['localization'] = read_localization(data_file_paths.localization())\n",
    "    testcase_data['control'] = read_control(data_file_paths.control())\n",
    "    testcase_data['metadata'] = read_metadata(data_file_paths.metadata())\n",
    "    if is_test:\n",
    "        testcase_data['requested_stamps'] = read_requested_stamps(data_file_paths.requested_stamps())\n",
    "        \n",
    "    return testcase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testcases(dataset_path: str, is_test: bool = False, testcase_ids: typing.Iterable[int] = None):\n",
    "    result = {}\n",
    "    if testcase_ids is None:\n",
    "        testcase_ids = read_testcase_ids(dataset_path)\n",
    "    \n",
    "    for testcase_id in tqdm(testcase_ids):\n",
    "        testcase = read_testcase(dataset_path, testcase_id, is_test=is_test)\n",
    "        result[testcase_id] = testcase\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42000/42000 [03:51<00:00, 181.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# may take some time\n",
    "train_dataset = read_testcases(TRAIN_DATASET_PATH,  testcase_ids = train_ids[:])\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:35<00:00, 228.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = read_testcases(TEST_DATASET_PATH, is_test=True)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_models = []\n",
    "vehicle_modifications = []\n",
    "tires_types = []\n",
    "location_ids = []\n",
    "vehicle_ids = []\n",
    "\n",
    "\n",
    "for testcase in train_dataset.values():\n",
    "    metadata = testcase['metadata']\n",
    "    vehicle_ids.append(metadata['vehicle_id'])\n",
    "    vehicle_models.append(metadata['vehicle_model'])\n",
    "    vehicle_modifications.append(metadata['vehicle_model_modification'])\n",
    "    location_ids.append(metadata['location_reference_point_id'])\n",
    "    tires_types.append(metadata['tires']['front'])\n",
    "    tires_types.append(metadata['tires']['rear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_vehicle_model_idx = Counter(vehicle_models).most_common()[0][0]\n",
    "unknown_vehicle_modification_idx = Counter(vehicle_modifications).most_common()[0][0]\n",
    "unknown_tires_idx = Counter(tires_types).most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_ids = set(vehicle_ids)\n",
    "vehicle_models = set(vehicle_models)\n",
    "vehicle_modifications = set(vehicle_modifications)\n",
    "tires_types = set(tires_types)\n",
    "location_ids = set(location_ids)\n",
    "\n",
    "\n",
    "vehicle_model_mapping = {label: idx for idx, label in enumerate(vehicle_models)}\n",
    "vehicle_modification_mapping = {label: idx for idx, label in enumerate(vehicle_modifications)}\n",
    "tires_mapping = {label: idx for idx, label in enumerate(tires_types)}\n",
    "\n",
    "# unknown_vehicle_model_idx = len(vehicle_models)\n",
    "# unknown_vehicle_modification_idx = len(vehicle_modifications)\n",
    "# unknown_tires_idx = len(tires_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_identifiers(identifiers, val_ratio=0.2):\n",
    "    identifiers = list(identifiers)\n",
    "    random.shuffle(identifiers)\n",
    "    val_size = int(len(identifiers) * val_ratio)\n",
    "    val_identifiers = set(identifiers[:val_size])\n",
    "    train_identifiers = set(identifiers[val_size:])\n",
    "    return train_identifiers, val_identifiers\n",
    "\n",
    "# Split location_reference_point_id\n",
    "train_location_ids, val_location_ids = split_identifiers(location_ids, val_ratio=val_ratio)\n",
    "\n",
    "# Optionally, split vehicle_ids and vehicle_models similarly\n",
    "train_vehicle_ids, val_vehicle_ids = split_identifiers(vehicle_ids)\n",
    "train_vehicle_models, val_vehicle_models = split_identifiers(vehicle_modifications)\n",
    "train_data = {}\n",
    "val_data = {}\n",
    "\n",
    "for testcase_id, testcase in train_dataset.items():\n",
    "    metadata = testcase['metadata']\n",
    "    location_id = metadata['location_reference_point_id']\n",
    "    vehicle_id = metadata['vehicle_id']\n",
    "    vehicle_model = metadata['vehicle_model']\n",
    "    \n",
    "    # Determine whether to include the sample in training or validation set\n",
    "    if (location_id in train_location_ids and\n",
    "        vehicle_id in train_vehicle_ids and\n",
    "        vehicle_model in train_vehicle_models):\n",
    "        train_data[testcase_id] = testcase\n",
    "    else:\n",
    "        val_data[testcase_id] = testcase\n",
    "\n",
    "# Check for overlaps\n",
    "assert not set(train_data.keys()) & set(val_data.keys()), \"Overlap between training and validation sets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, dataset, training=True):\n",
    "        self.data = []\n",
    "        sampling_interval_ns = 4e7  # 0.04 seconds in nanoseconds\n",
    "        initial_state_length = int(5 / 0.04)  # Steps for initial 5 seconds (125 steps)\n",
    "        target_length = int(15 / 0.04)  # Steps from 5s to 20s (375 steps)\n",
    "        sequence_length = initial_state_length + target_length  # Total steps (500 steps)\n",
    "\n",
    "        for testcase_id, testcase in tqdm(dataset.items()):\n",
    "            metadata = testcase['metadata']\n",
    "            vehicle_features = self.encode_vehicle_features(metadata)\n",
    "\n",
    "            # Get control commands\n",
    "            control = testcase['control']\n",
    "            control['acceleration_level'] = control['acceleration_level']\n",
    "            control_seq = control[['stamp_ns', 'acceleration_level', 'steering']].values\n",
    "\n",
    "            # Get localization data\n",
    "            localization = testcase['localization']\n",
    "            localization_seq = localization[['stamp_ns', 'x', 'y', 'z', 'roll', 'pitch', 'yaw']].values\n",
    "    \n",
    "            time_steps = np.arange(0, 60 * 1e9, sampling_interval_ns)\n",
    "            control_resampled = self.resample_sequence(control_seq, time_steps)\n",
    "            control_resampled = control_resampled[:, 1:] # drop ns\n",
    "            localization_resampled = self.resample_sequence(localization_seq, time_steps)\n",
    "            localization_resampled = localization_resampled[:, 1:] # drop ns\n",
    "            \n",
    "            max_start_idx = len(time_steps) - sequence_length\n",
    "            for i in range(0, max_start_idx, initial_state_length):  # Slide window\n",
    "                # Initial localization sequence (first 5 seconds)\n",
    "                \n",
    "                input_localization = deepcopy(localization_resampled[i:i+initial_state_length])  # Shape: [125, 3]\n",
    "                \n",
    "                start_position = deepcopy(input_localization[0][:3])\n",
    "                \n",
    "                input_localization[:, :3] -= start_position # Shift initial localization to zero\n",
    "                \n",
    "                # Target trajectory from t + 5s to t + 20s\n",
    "                output_localization = deepcopy(localization_resampled[i+initial_state_length:i+sequence_length]) # Shape: [375, 3]\n",
    "                output_localization[:, :3] -= start_position\n",
    "            \n",
    "                # Initial and inference control sequence\n",
    "                input_control_sequence = deepcopy(control_resampled[i:i+initial_state_length])\n",
    "                output_control_sequence = deepcopy(control_resampled[i+initial_state_length:i+sequence_length])\n",
    "                \n",
    "            \n",
    "                self.data.append({\n",
    "                    'vehicle_features': vehicle_features,\n",
    "                    'input_localization': input_localization,\n",
    "                    'output_localization': output_localization,\n",
    "                    'input_control_sequence': input_control_sequence,\n",
    "                    'output_control_sequence': output_control_sequence,\n",
    "                })\n",
    "\n",
    "    def encode_vehicle_features(self, metadata):\n",
    "        vehicle_model = vehicle_model_mapping.get(metadata['vehicle_model'], unknown_vehicle_model_idx)\n",
    "        vehicle_modification = vehicle_modification_mapping.get(metadata['vehicle_model_modification'], unknown_vehicle_modification_idx)\n",
    "        tires_front = tires_mapping.get(metadata['tires']['front'], unknown_tires_idx)\n",
    "        tires_rear = tires_mapping.get(metadata['tires']['rear'], unknown_tires_idx)\n",
    "        vehicle_features = [vehicle_model, vehicle_modification, tires_front, tires_rear]\n",
    "        return vehicle_features\n",
    "\n",
    "    def resample_sequence(self, seq, time_steps):\n",
    "        df_seq = pd.DataFrame(seq, columns=['stamp_ns'] + [f'feat_{i}' for i in range(seq.shape[1]-1)])\n",
    "        df_seq = df_seq.set_index('stamp_ns').reindex(time_steps, method='nearest').reset_index()\n",
    "        return df_seq.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tensor_dict = {}\n",
    "        for k, v in sample.items():\n",
    "            if k.startswith('vehicle'):\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.long)\n",
    "            else:\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.float32)\n",
    "        return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 745/33831 [00:03<02:33, 214.86it/s]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataset = TrajectoryDataset(dict(itertools.islice(train_data.items(), 10)), training=True)\n",
    "# val_dataset = TrajectoryDataset(dict(itertools.islice(val_data.items(), 10)), training=False)\n",
    "\n",
    "train_dataset = TrajectoryDataset(train_data, training=True)\n",
    "val_dataset = TrajectoryDataset(val_data, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in [-3, -2, -1]:\n",
    "    print(batch['input_localization'][batch_id][ind][:3])\n",
    "for ind in [0, 1, 2, 3]:\n",
    "    print(batch['output_localization'][batch_id][ind][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryEncoderDecoder(nn.Module):\n",
    "    def __init__(self, vehicle_feature_sizes, embedding_dim, localization_input_size, control_input_size, hidden_size, num_layers):\n",
    "        super(TrajectoryEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Vehicle feature embeddings\n",
    "        self.vehicle_model_embedding = nn.Embedding(num_embeddings=vehicle_feature_sizes['vehicle_model'], embedding_dim=embedding_dim)\n",
    "        self.vehicle_modification_embedding = nn.Embedding(num_embeddings=vehicle_feature_sizes['vehicle_modification'], embedding_dim=embedding_dim)\n",
    "        self.tires_embedding = nn.Embedding(num_embeddings=vehicle_feature_sizes['tires'], embedding_dim=embedding_dim)\n",
    "\n",
    "        # Fully connected layer to combine vehicle features\n",
    "        self.vehicle_fc = nn.Linear(embedding_dim * 4, hidden_size)\n",
    "\n",
    "        # Encoder LSTM for localization\n",
    "        self.localization_encoder = nn.LSTM(input_size=localization_input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Encoder LSTM for control sequence\n",
    "        self.control_encoder = nn.LSTM(input_size=control_input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Decoder LSTM\n",
    "        self.decoder = nn.LSTM(input_size=control_input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(hidden_size, localization_input_size)\n",
    "\n",
    "    def forward(self, vehicle_features, input_localization, input_control_sequence, output_control_sequence):\n",
    "        batch_size = input_localization.size(0)\n",
    "\n",
    "        # Embed vehicle features\n",
    "        vehicle_model = self.vehicle_model_embedding(vehicle_features[:, 0])\n",
    "        vehicle_modification = self.vehicle_modification_embedding(vehicle_features[:, 1])\n",
    "        tires_front = self.tires_embedding(vehicle_features[:, 2])\n",
    "        tires_rear = self.tires_embedding(vehicle_features[:, 3])\n",
    "\n",
    "        # Concatenate vehicle features\n",
    "        vehicle_embedded = torch.cat([vehicle_model, vehicle_modification, tires_front, tires_rear], dim=1)\n",
    "        vehicle_features_encoded = self.vehicle_fc(vehicle_embedded)  # Shape: [batch_size, hidden_size]\n",
    "\n",
    "        # Encoder for localization\n",
    "        _, (hidden_loc, cell_loc) = self.localization_encoder(input_localization)  # hidden_loc: [num_layers, batch_size, hidden_size]\n",
    "\n",
    "        # Encoder for control sequence\n",
    "        _, (hidden_ctrl, cell_ctrl) = self.control_encoder(input_control_sequence)  # hidden_ctrl: [num_layers, batch_size, hidden_size]\n",
    "\n",
    "        # Combine encoder hidden states and vehicle features\n",
    "        # Option to concatenate, sum, or average hidden states\n",
    "        hidden_enc = (hidden_loc + hidden_ctrl) / 2  # Shape: [num_layers, batch_size, hidden_size]\n",
    "        cell_enc = (cell_loc + cell_ctrl) / 2\n",
    "\n",
    "        # Incorporate vehicle features into the hidden state\n",
    "        # We'll add vehicle_features_encoded to the first layer's hidden state\n",
    "        hidden_enc[0] = hidden_enc[0] + vehicle_features_encoded.unsqueeze(0)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_output, _ = self.decoder(output_control_sequence, (hidden_enc, cell_enc))  # decoder_output: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # Output layer\n",
    "        output_localization = self.fc_out(decoder_output)  # Shape: [batch_size, seq_len, localization_input_size]\n",
    "\n",
    "        return output_localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define embedding sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sizes based on your data\n",
    "vehicle_feature_sizes = {\n",
    "    'vehicle_model': len(vehicle_model_mapping),\n",
    "    'vehicle_modification': len(vehicle_modification_mapping),\n",
    "    'tires': len(tires_mapping),\n",
    "}\n",
    "\n",
    "embedding_dim = 16\n",
    "localization_input_size = 6  # For example, x, y, z, roll, pitch, yaw\n",
    "control_input_size = 2  # acceleration_level, steering\n",
    "hidden_size = 128\n",
    "num_layers = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEGMENT_LENGTH = 1.0\n",
    "\n",
    "def calculate_metric_on_batch(output_np, target_np, segment_length=1.0):\n",
    "    \"\"\"\n",
    "    output_np: numpy array of shape [batch_size, seq_len, 4], predicted x, y, yaw\n",
    "    target_np: numpy array of same shape, ground truth x, y, yaw\n",
    "\n",
    "    Returns:\n",
    "        metric: float, the average metric over the batch\n",
    "    \"\"\"\n",
    "    x_pred, y_pred, yaw_pred = output_np[..., 0], output_np[..., 1], output_np[..., 2]\n",
    "    x_gt, y_gt, yaw_gt = target_np[..., 0], target_np[..., 1], target_np[..., 2]\n",
    "\n",
    "    # Compute c1 and c2 for predicted\n",
    "    c1_pred = np.stack([x_pred, y_pred], axis=-1)\n",
    "    c2_pred = c1_pred + segment_length * np.stack([np.cos(yaw_pred), np.sin(yaw_pred)], axis=-1)\n",
    "\n",
    "    # Compute c1 and c2 for ground truth\n",
    "    c1_gt = np.stack([x_gt, y_gt], axis=-1)\n",
    "    c2_gt = c1_gt + segment_length * np.stack([np.cos(yaw_gt), np.sin(yaw_gt)], axis=-1)\n",
    "\n",
    "    # Compute distances between corresponding points\n",
    "    dist_c1 = np.linalg.norm(c1_pred - c1_gt, axis=-1)\n",
    "    dist_c2 = np.linalg.norm(c2_pred - c2_gt, axis=-1)\n",
    "\n",
    "    # Compute pose metric\n",
    "    pose_metric = np.sqrt((dist_c1 ** 2 + dist_c2 ** 2) / 2.0)\n",
    "    metric = np.mean(pose_metric)\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TrajectoryEncoderDecoder(\n",
    "    vehicle_feature_sizes=vehicle_feature_sizes,\n",
    "    embedding_dim=embedding_dim,\n",
    "    localization_input_size=localization_input_size,\n",
    "    control_input_size=control_input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 40\n",
    "best_val_loss = 100000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_metric = 0\n",
    "    for sample in tqdm(train_loader):\n",
    "        vehicle_features = sample['vehicle_features'].to(device)\n",
    "        input_localization = sample['input_localization'].to(device)\n",
    "        output_localization = sample['output_localization'].to(device)\n",
    "        input_control_sequence = sample['input_control_sequence'].to(device)\n",
    "        output_control_sequence = sample['output_control_sequence'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output_localization = model(\n",
    "            vehicle_features,\n",
    "            input_localization,\n",
    "            input_control_sequence,\n",
    "            output_control_sequence\n",
    "        )\n",
    "        loss = criterion(predicted_output_localization, output_localization)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        predicted_x_y_yaw = predicted_output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "        gt_x_y_yaw = output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "        batch_metric = calculate_metric_on_batch(predicted_x_y_yaw, gt_x_y_yaw)\n",
    "        epoch_metric += batch_metric\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    avg_metric = epoch_metric / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_loss:.4f}, Metric: {avg_metric:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_metric = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(val_loader):\n",
    "            vehicle_features = sample['vehicle_features'].to(device)\n",
    "            input_localization = sample['input_localization'].to(device)\n",
    "            output_localization = sample['output_localization'].to(device)\n",
    "            input_control_sequence = sample['input_control_sequence'].to(device)\n",
    "            output_control_sequence = sample['output_control_sequence'].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            predicted_output_localization = model(\n",
    "                vehicle_features,\n",
    "                input_localization,\n",
    "                input_control_sequence,\n",
    "                output_control_sequence\n",
    "            )\n",
    "            loss = criterion(predicted_output_localization, output_localization)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_x_y_yaw = predicted_output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "            gt_x_y_yaw = output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "            batch_metric = calculate_metric_on_batch(predicted_x_y_yaw, gt_x_y_yaw)\n",
    "            val_metric += batch_metric\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.jit.save(torch.jit.script(model), 'best.pt')\n",
    "        \n",
    "    avg_val_metric = val_metric / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Metric: {avg_val_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:10<00:00, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 14.1419, Metric: 5.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0\n",
    "val_metric = 0\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(val_loader):\n",
    "        vehicle_features = sample['vehicle_features'].to(device)\n",
    "        input_localization = sample['input_localization'].to(device)\n",
    "        output_localization = sample['output_localization'].to(device)\n",
    "        input_control_sequence = sample['input_control_sequence'].to(device)\n",
    "        output_control_sequence = sample['output_control_sequence'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output_localization = model(\n",
    "            vehicle_features,\n",
    "            input_localization,\n",
    "            input_control_sequence,\n",
    "            output_control_sequence\n",
    "        )\n",
    "        loss = criterion(predicted_output_localization, output_localization)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        predicted_x_y_yaw = predicted_output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "        gt_x_y_yaw = output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "        batch_metric = calculate_metric_on_batch(predicted_x_y_yaw, gt_x_y_yaw)\n",
    "        val_metric += batch_metric\n",
    "        \n",
    "avg_val_loss = val_loss / len(val_loader)\n",
    "if avg_val_loss < best_val_loss:\n",
    "    best_val_loss = avg_val_loss\n",
    "    torch.jit.save(torch.jit.script(model), 'best.pt')\n",
    "    \n",
    "avg_val_metric = val_metric / len(val_loader)\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}, Metric: {avg_val_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataset_path):\n",
    "        self.data = []\n",
    "        sampling_interval_ns = 4e7  # 0.04 seconds in nanoseconds\n",
    "        initial_state_length = int(5 / 0.04)  # 125 steps\n",
    "        target_length = int(15 / 0.04)        # 375 steps\n",
    "        sequence_length = initial_state_length + target_length  # 500 steps\n",
    "\n",
    "        # Get list of test case IDs (folder names)\n",
    "        testcase_ids = sorted([name for name in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, name))])\n",
    "\n",
    "        for testcase_id in tqdm(testcase_ids):\n",
    "            testcase_path = os.path.join(dataset_path, testcase_id)\n",
    "\n",
    "            # Load metadata and encode vehicle features\n",
    "            with open(os.path.join(testcase_path, 'metadata.json'), 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            vehicle_features = self.encode_vehicle_features(metadata)\n",
    "\n",
    "            # Load localization data (first 5 seconds)\n",
    "            localization = pd.read_csv(os.path.join(testcase_path, 'localization.csv'))\n",
    "            localization_seq = localization[['stamp_ns', 'x', 'y', 'z', 'roll', 'pitch', 'yaw']].values\n",
    "\n",
    "            # Load control data (first 20 seconds)\n",
    "            control = pd.read_csv(os.path.join(testcase_path, 'control.csv'))\n",
    "            control['acceleration_level'] = control['acceleration_level'].fillna(0)\n",
    "            control_seq = control[['stamp_ns', 'acceleration_level', 'steering']].values\n",
    "\n",
    "            # Load requested stamps\n",
    "            requested_stamps = pd.read_csv(os.path.join(testcase_path, 'requested_stamps.csv'))['stamp_ns'].values\n",
    "\n",
    "            # Resample sequences to fixed time steps\n",
    "            time_steps_localization = np.arange(0, 5 * 1e9, sampling_interval_ns)\n",
    "            time_steps_control = np.arange(0, 20 * 1e9, sampling_interval_ns)\n",
    "\n",
    "            localization_resampled = self.resample_sequence(localization_seq, time_steps_localization)\n",
    "            control_resampled = self.resample_sequence(control_seq, time_steps_control)\n",
    "\n",
    "            # Process localization data\n",
    "            localization_resampled = localization_resampled[:, 1:]  # Drop stamp_ns\n",
    "            input_localization = localization_resampled.copy()      # Shape: [125, 7]\n",
    "\n",
    "            # Subtract start position\n",
    "            start_position = input_localization[0, :3].copy()\n",
    "            input_localization[:, :3] -= start_position\n",
    "\n",
    "            # Prepare input_control_sequence (first 5 seconds)\n",
    "            control_resampled = control_resampled[:, 1:]  # Drop stamp_ns\n",
    "            input_control_sequence = control_resampled[:initial_state_length].copy()  # [125, 2]\n",
    "\n",
    "            # Prepare output_control_sequence (from 5s to 20s)\n",
    "            output_control_sequence = control_resampled[initial_state_length:].copy()  # [375, 2]\n",
    "\n",
    "            self.data.append({\n",
    "                'testcase_id': int(testcase_id),\n",
    "                'vehicle_features': vehicle_features,\n",
    "                'input_localization': input_localization,\n",
    "                'input_control_sequence': input_control_sequence,\n",
    "                'output_control_sequence': output_control_sequence,\n",
    "                'start_position': start_position,\n",
    "                'requested_stamps': requested_stamps\n",
    "            })\n",
    "\n",
    "    def encode_vehicle_features(self, metadata):\n",
    "        vehicle_model = vehicle_model_mapping.get(metadata['vehicle_model'], unknown_vehicle_model_idx)\n",
    "        vehicle_modification = vehicle_modification_mapping.get(metadata['vehicle_model_modification'], unknown_vehicle_modification_idx)\n",
    "        tires_front = tires_mapping.get(metadata['tires']['front'], unknown_tires_idx)\n",
    "        tires_rear = tires_mapping.get(metadata['tires']['rear'], unknown_tires_idx)\n",
    "        vehicle_features = [vehicle_model, vehicle_modification, tires_front, tires_rear]\n",
    "        return vehicle_features\n",
    "\n",
    "    def resample_sequence(self, seq, time_steps):\n",
    "        df_seq = pd.DataFrame(seq, columns=['stamp_ns'] + [f'feat_{i}' for i in range(seq.shape[1]-1)])\n",
    "        df_seq = df_seq.set_index('stamp_ns').reindex(time_steps, method='nearest').reset_index()\n",
    "        return df_seq.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tensor_dict = {}\n",
    "        for k, v in sample.items():\n",
    "            if k == 'vehicle_features':\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.long)\n",
    "            elif k in ['input_localization', 'input_control_sequence', 'output_control_sequence']:\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.float32)\n",
    "            else:\n",
    "                tensor_dict[k] = v  # Keep as is (e.g., start_position, requested_stamps, testcase_id)\n",
    "        return tensor_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [01:01<00:00, 130.69it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(TEST_DATASET_PATH)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_length = 125\n",
    "target_length = 375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:37<00:00, 215.37it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(test_loader):\n",
    "        testcase_id = sample['testcase_id'][0].item()\n",
    "        vehicle_features = sample['vehicle_features'].to(device)\n",
    "        input_localization = sample['input_localization'].to(device)\n",
    "        input_control_sequence = sample['input_control_sequence'].to(device)\n",
    "        output_control_sequence = sample['output_control_sequence'].to(device)\n",
    "        start_position = sample['start_position'][0].numpy()\n",
    "        requested_stamps = sample['requested_stamps'][0].numpy()\n",
    "\n",
    "        # Check sequence lengths\n",
    "        if input_localization.size(1) != initial_state_length:\n",
    "            print(f\"Skipping {testcase_id}: input_localization length mismatch\")\n",
    "            continue\n",
    "        if input_control_sequence.size(1) != initial_state_length:\n",
    "            print(f\"Skipping {testcase_id}: input_control_sequence length mismatch\")\n",
    "            continue\n",
    "        if output_control_sequence.size(1) != target_length:\n",
    "            print(f\"Skipping {testcase_id}: output_control_sequence length mismatch\")\n",
    "            continue\n",
    "\n",
    "        # Forward pass\n",
    "        try:\n",
    "            predicted_output_localization = model(\n",
    "                vehicle_features,\n",
    "                input_localization,\n",
    "                input_control_sequence,\n",
    "                output_control_sequence\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {testcase_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        predicted_output_localization = predicted_output_localization.detach().cpu().numpy()[0]\n",
    "        predicted_output_localization[:, :3] += start_position\n",
    "        \n",
    "        # Get x, y positions, yaw\n",
    "        yaw_pred = predicted_output_localization[:, -1]\n",
    "        x_pred = predicted_output_localization[:, 0]\n",
    "        y_pred = predicted_output_localization[:, 1]\n",
    "\n",
    "        # Time steps corresponding to output predictions (from 5s to 20s every 0.04s)\n",
    "        time_steps = np.arange(5 * 1e9, 20 * 1e9, 4e7)  # [375]\n",
    "\n",
    "        # Map requested_stamps to indices in time_steps\n",
    "        indices = np.searchsorted(time_steps, requested_stamps)\n",
    "        \n",
    "        # Handle any indices out of bounds\n",
    "        indices = np.clip(indices, 0, len(time_steps) - 1)\n",
    "\n",
    "        # Extract predictions at requested timestamps\n",
    "        x_pred = x_pred[indices]\n",
    "        y_pred = y_pred[indices]\n",
    "        yaw_pred = yaw_pred[indices]\n",
    "\n",
    "        # Collect predictions\n",
    "        for stamp_ns, x, y, yaw in zip(requested_stamps, x_pred, y_pred, yaw_pred):\n",
    "            predictions.append({\n",
    "                'testcase_id': testcase_id,\n",
    "                'stamp_ns': int(stamp_ns),\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'yaw': yaw\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testcase_id    False\n",
       "stamp_ns       False\n",
       "x              False\n",
       "y              False\n",
       "yaw            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testcase_id</th>\n",
       "      <th>stamp_ns</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5000888836</td>\n",
       "      <td>-1490.079346</td>\n",
       "      <td>-1318.720703</td>\n",
       "      <td>2.238707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5040043013</td>\n",
       "      <td>-1491.794434</td>\n",
       "      <td>-1318.204834</td>\n",
       "      <td>2.176710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5079989560</td>\n",
       "      <td>-1491.794434</td>\n",
       "      <td>-1318.204834</td>\n",
       "      <td>2.176710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5120797471</td>\n",
       "      <td>-1494.852295</td>\n",
       "      <td>-1316.256470</td>\n",
       "      <td>2.027777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5165218288</td>\n",
       "      <td>-1494.279053</td>\n",
       "      <td>-1314.014282</td>\n",
       "      <td>1.822948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   testcase_id    stamp_ns            x            y       yaw\n",
       "0            0  5000888836 -1490.079346 -1318.720703  2.238707\n",
       "1            0  5040043013 -1491.794434 -1318.204834  2.176710\n",
       "2            0  5079989560 -1491.794434 -1318.204834  2.176710\n",
       "3            0  5120797471 -1494.852295 -1316.256470  2.027777\n",
       "4            0  5165218288 -1494.279053 -1314.014282  1.822948"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('finally_rnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 5)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.explode(column=['stamp_ns', 'x', 'y', 'yaw']).to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NSECS_IN_SEC = 1000000000\n",
    "\n",
    "def secs_to_nsecs(secs: float):\n",
    "    return int(secs * NSECS_IN_SEC)\n",
    "\n",
    "def nsecs_to_secs(nsecs: int):\n",
    "    return float(nsecs) / NSECS_IN_SEC\n",
    "\n",
    "def yaw_direction(yaw_value):\n",
    "    return np.array([np.cos(yaw_value), np.sin(yaw_value)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple pose prediction logic without taking into account control states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_df_to_poses(loc_df):\n",
    "    poses = []\n",
    "    for stamp_ns, x, y, yaw in zip(loc_df['stamp_ns'], loc_df['x'], loc_df['y'], loc_df['yaw']):\n",
    "        poses.append({'stamp_ns': stamp_ns, 'pos': np.array([x, y]), 'yaw': yaw})\n",
    "    return poses\n",
    "\n",
    "# naive estimation of speed at last known localization pose\n",
    "def dummy_estimate_last_speed(localization_poses):\n",
    "    last_pose = localization_poses[-1]\n",
    "    \n",
    "    start_pose_idx = -1\n",
    "    for i, pose in enumerate(localization_poses, start=1-len(localization_poses)):\n",
    "        start_pose_idx = i\n",
    "        if nsecs_to_secs(last_pose['stamp_ns']) - nsecs_to_secs(pose['stamp_ns']) > 1.: # sec\n",
    "            break\n",
    "            \n",
    "    start_pose = localization_poses[start_pose_idx]\n",
    "    dt_sec = nsecs_to_secs(last_pose['stamp_ns']) - nsecs_to_secs(start_pose['stamp_ns'])\n",
    "    \n",
    "    if dt_sec > 1e-5:\n",
    "        return np.linalg.norm(last_pose['pos'][:2] - start_pose['pos'][:2]) / dt_sec\n",
    "    return 5. # some default value\n",
    "\n",
    "def dummpy_predict_pose(last_loc_pose: dict, last_speed: float, prediction_stamp: int):\n",
    "    dt_sec = nsecs_to_secs(prediction_stamp) - nsecs_to_secs(last_loc_pose['stamp_ns'])\n",
    "    distance = dt_sec * last_speed\n",
    "    direction = yaw_direction(last_loc_pose['yaw'])\n",
    "    pos_translate = direction * distance\n",
    "    return {\"pos\": last_loc_pose['pos'] + pos_translate, 'yaw': last_loc_pose['yaw']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_testcase(testcase: dict):\n",
    "    loc_df = testcase['localization']\n",
    "    localization_poses = localization_df_to_poses(loc_df)\n",
    "    \n",
    "    last_loc_pose = localization_poses[-1]\n",
    "    last_speed = dummy_estimate_last_speed(localization_poses)\n",
    "    \n",
    "    predicted_poses = []\n",
    "    for stamp in testcase['requested_stamps']['stamp_ns']:\n",
    "        pose = dummpy_predict_pose(last_loc_pose, last_speed, stamp)\n",
    "        predicted_poses.append(pose)\n",
    "        \n",
    "    predictions = {}\n",
    "    predictions['stamp_ns'] = testcase['requested_stamps']['stamp_ns']\n",
    "    predictions['x'] = [pose['pos'][0] for pose in predicted_poses]\n",
    "    predictions['y'] = [pose['pos'][1] for pose in predicted_poses]\n",
    "    predictions['yaw'] = [pose['yaw'] for pose in predicted_poses]\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "def predict_test_dataset(test_dataset: dict):\n",
    "    predictions = {}\n",
    "    for testcase_id, testcase in tqdm(test_dataset.items()): \n",
    "        predictions[testcase_id] = predict_testcase(testcase)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make prediction for requested stamps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:23<00:00, 343.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = predict_test_dataset(test_dataset)\n",
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(dataset_predictions: dict, prediction_file_path: str):\n",
    "    prediction_list = []\n",
    "    for testcase_id, prediction in tqdm(dataset_predictions.items()):\n",
    "        prediction['testcase_id'] = [testcase_id] * len(prediction)\n",
    "        prediction_list.append(prediction)\n",
    "    predictions_df = pd.concat(prediction_list)\n",
    "    predictions_df = predictions_df.reindex(columns=[\"testcase_id\", \"stamp_ns\", \"x\", \"y\", \"yaw\"])\n",
    "    print(len(predictions_df))\n",
    "    predictions_df.to_csv(prediction_file_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:01<00:00, 4018.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998763\n"
     ]
    }
   ],
   "source": [
    "write_predictions(test_predictions, os.path.join(ROOT_DATA_FOLDER, \"dummy_prediction.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./YandexCup2024v2'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_prediction = pd.read_csv('./YandexCup2024v2/dummy_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testcase_id</th>\n",
       "      <th>stamp_ns</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5000888836</td>\n",
       "      <td>-1490.905035</td>\n",
       "      <td>-1310.813635</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5040043013</td>\n",
       "      <td>-1490.955001</td>\n",
       "      <td>-1310.716927</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5079989560</td>\n",
       "      <td>-1491.005979</td>\n",
       "      <td>-1310.618261</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5120797471</td>\n",
       "      <td>-1491.058057</td>\n",
       "      <td>-1310.517468</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5165218288</td>\n",
       "      <td>-1491.114744</td>\n",
       "      <td>-1310.407751</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   testcase_id    stamp_ns            x            y       yaw\n",
       "0            0  5000888836 -1490.905035 -1310.813635  2.047693\n",
       "1            0  5040043013 -1490.955001 -1310.716927  2.047693\n",
       "2            0  5079989560 -1491.005979 -1310.618261  2.047693\n",
       "3            0  5120797471 -1491.058057 -1310.517468  2.047693\n",
       "4            0  5165218288 -1491.114744 -1310.407751  2.047693"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2998763, 5)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_prediction.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe final metric. As a first step, all predicted triples $(x,y,yaw)$ are being converted into 2 points $[(x_1, y_1), (x_2, y_2)]$ in the following way:\n",
    "$$\n",
    "(x_1, y_1) = (x, y), \\\\\n",
    "(x_2, y_2) = (x_1, y_1) + S \\times (yaw_x, yaw_y)\n",
    "$$  \n",
    "\n",
    "where $S = 1$. In other words, we build a directed segment of length $1$. These points then used in the metric calculation.\n",
    "\n",
    "\n",
    "Metric for a single pose (rmse):\n",
    "\n",
    "$$\n",
    "pose\\_metric = \\sqrt{ \\frac{\\displaystyle\\sum_{j=1}^{k} {(x_j-\\hat{x_j})^2 + (y_j-\\hat{y_j})^2}}{k} }\n",
    "$$\n",
    "\n",
    "where $k$ - number of points that describe single pose (in our case $k=2$).\n",
    "\n",
    "Metric for a testcase:\n",
    "\n",
    "$$\n",
    "testcase\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}pose\\_metric_i\n",
    "$$\n",
    "\n",
    "where $n$ - number of localization points to predict.\n",
    "\n",
    "And, final metric for a whole dataset:\n",
    "\n",
    "$$\n",
    "dataset\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}testcase\\_metric_i\n",
    "$$\n",
    "\n",
    "where $n$ - number of test cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementation of the metric calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEGMENT_LENGTH = 1.\n",
    "\n",
    "def yaw_direction(yaw_value):\n",
    "    return np.array([np.cos(yaw_value), np.sin(yaw_value)])\n",
    "\n",
    "def build_car_points(x_y_yaw):\n",
    "    directions = np.vstack(yaw_direction(x_y_yaw[:, -1]))\n",
    "    \n",
    "    front_points = x_y_yaw[:, :-1] + SEGMENT_LENGTH * directions.T\n",
    "    points = np.vstack([x_y_yaw[:, :-1], front_points])\n",
    "    return points\n",
    "\n",
    "def build_car_points_from_merged_df(df: pd.DataFrame):\n",
    "    points_gt = df[['x_gt', 'y_gt', 'yaw_gt']].to_numpy()\n",
    "    points_pred = df[['x_pred', 'y_pred', 'yaw_pred']].to_numpy()\n",
    "    \n",
    "    points_gt = build_car_points(points_gt)\n",
    "    points_pred = build_car_points(points_pred)\n",
    "    return points_gt, points_pred\n",
    "\n",
    "def calculate_metric_testcase(df: pd.DataFrame):        \n",
    "    points_gt, points_pred = build_car_points_from_merged_df(df)\n",
    "    \n",
    "    metric = np.mean(np.sqrt(2. * np.mean((points_gt - points_pred) ** 2, axis=1)))\n",
    "    return metric\n",
    "\n",
    "def calculate_metric_dataset(ground_truth_df: pd.DataFrame, prediction_df: pd.DataFrame):\n",
    "    assert (len(ground_truth_df) == len(prediction_df))\n",
    "    \n",
    "    df = ground_truth_df.merge(prediction_df, on=['testcase_id', 'stamp_ns'], suffixes=['_gt', '_pred'])\n",
    "    \n",
    "    metric = df.groupby('testcase_id').apply(calculate_metric_testcase)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
