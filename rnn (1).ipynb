{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_FOLDER = \"./YandexCup2024v2\"\n",
    "\n",
    "TRAIN_DATASET_PATH = os.path.join(ROOT_DATA_FOLDER, \"YaCupTrain\")\n",
    "TEST_DATASET_PATH = os.path.join(ROOT_DATA_FOLDER, \"YaCupTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all ids of a dataset\n",
    "\n",
    "def read_testcase_ids(dataset_path: str):\n",
    "    ids = [int(case_id) for case_id in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, case_id))]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = read_testcase_ids(TRAIN_DATASET_PATH)\n",
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = read_testcase_ids(TEST_DATASET_PATH)\n",
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFilePaths:\n",
    "    def __init__(self, testcase_path: str):\n",
    "        self.testcase_path = testcase_path\n",
    "        \n",
    "    def localization(self):\n",
    "        return os.path.join(self.testcase_path, 'localization.csv')\n",
    "    \n",
    "    def control(self):\n",
    "        return os.path.join(self.testcase_path, 'control.csv')\n",
    "    \n",
    "    def metadata(self):\n",
    "        return os.path.join(self.testcase_path, 'metadata.json')\n",
    "    \n",
    "    # exists only for test_dataset\n",
    "    def requested_stamps(self):\n",
    "        return os.path.join(self.testcase_path, 'requested_stamps.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def read_localization(localization_path: str):\n",
    "    return pd.read_csv(localization_path)\n",
    "\n",
    "def read_control(control_path):\n",
    "    return pd.read_csv(control_path)\n",
    "\n",
    "def read_metadata(metadata_path: str):\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def read_requested_stamps(requested_stamps_path: str):\n",
    "    return pd.read_csv(requested_stamps_path)\n",
    "    \n",
    "def read_testcase(dataset_path: str, testcase_id: str, is_test: bool = False):\n",
    "    testcase_path = os.path.join(dataset_path, str(testcase_id))\n",
    "    data_file_paths = DataFilePaths(testcase_path)\n",
    "    \n",
    "    testcase_data = {}\n",
    "    testcase_data['localization'] = read_localization(data_file_paths.localization())\n",
    "    testcase_data['control'] = read_control(data_file_paths.control())\n",
    "    testcase_data['metadata'] = read_metadata(data_file_paths.metadata())\n",
    "    if is_test:\n",
    "        testcase_data['requested_stamps'] = read_requested_stamps(data_file_paths.requested_stamps())\n",
    "        \n",
    "    return testcase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testcases(dataset_path: str, is_test: bool = False, testcase_ids: typing.Iterable[int] = None):\n",
    "    result = {}\n",
    "    if testcase_ids is None:\n",
    "        testcase_ids = read_testcase_ids(dataset_path)\n",
    "    \n",
    "    for testcase_id in tqdm(testcase_ids):\n",
    "        testcase = read_testcase(dataset_path, testcase_id, is_test=is_test)\n",
    "        result[testcase_id] = testcase\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 36257/42000 [04:04<00:38, 148.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# may take some time\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mread_testcases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_DATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtestcase_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mlen\u001b[39m(train_dataset)\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mread_testcases\u001b[0;34m(dataset_path, is_test, testcase_ids)\u001b[0m\n\u001b[1;32m      4\u001b[0m     testcase_ids \u001b[38;5;241m=\u001b[39m read_testcase_ids(dataset_path)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m testcase_id \u001b[38;5;129;01min\u001b[39;00m tqdm(testcase_ids):\n\u001b[0;32m----> 7\u001b[0m     testcase \u001b[38;5;241m=\u001b[39m \u001b[43mread_testcase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestcase_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     result[testcase_id] \u001b[38;5;241m=\u001b[39m testcase\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36mread_testcase\u001b[0;34m(dataset_path, testcase_id, is_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m data_file_paths \u001b[38;5;241m=\u001b[39m DataFilePaths(testcase_path)\n\u001b[1;32m     22\u001b[0m testcase_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 23\u001b[0m testcase_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mread_localization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file_paths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m testcase_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrol\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m read_control(data_file_paths\u001b[38;5;241m.\u001b[39mcontrol())\n\u001b[1;32m     25\u001b[0m testcase_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m read_metadata(data_file_paths\u001b[38;5;241m.\u001b[39mmetadata())\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mread_localization\u001b[0;34m(localization_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_localization\u001b[39m(localization_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocalization_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# may take some time\n",
    "train_dataset = read_testcases(TRAIN_DATASET_PATH,  testcase_ids = train_ids[:])\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = read_testcases(TEST_DATASET_PATH, is_test=True)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_models = []\n",
    "vehicle_modifications = []\n",
    "tires_types = []\n",
    "location_ids = []\n",
    "vehicle_ids = []\n",
    "\n",
    "\n",
    "for testcase in train_dataset.values():\n",
    "    metadata = testcase['metadata']\n",
    "    vehicle_ids.append(metadata['vehicle_id'])\n",
    "    vehicle_models.append(metadata['vehicle_model'])\n",
    "    vehicle_modifications.append(metadata['vehicle_model_modification'])\n",
    "    location_ids.append(metadata['location_reference_point_id'])\n",
    "    tires_types.append(metadata['tires']['front'])\n",
    "    tires_types.append(metadata['tires']['rear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_vehicle_model_idx = Counter(vehicle_models).most_common()[0][0]\n",
    "unknown_vehicle_modification_idx = Counter(vehicle_modifications).most_common()[0][0]\n",
    "unknown_tires_idx = Counter(tires_types).most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_ids = set(vehicle_ids)\n",
    "vehicle_models = set(vehicle_models)\n",
    "vehicle_modifications = set(vehicle_modifications)\n",
    "tires_types = set(tires_types)\n",
    "location_ids = set(location_ids)\n",
    "\n",
    "\n",
    "vehicle_model_mapping = {label: idx for idx, label in enumerate(vehicle_models)}\n",
    "vehicle_modification_mapping = {label: idx for idx, label in enumerate(vehicle_modifications)}\n",
    "tires_mapping = {label: idx for idx, label in enumerate(tires_types)}\n",
    "\n",
    "unknown_vehicle_model_idx = len(vehicle_models)\n",
    "unknown_vehicle_modification_idx = len(vehicle_modifications)\n",
    "unknown_tires_idx = len(tires_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_identifiers(identifiers, val_ratio=0.2):\n",
    "    identifiers = list(identifiers)\n",
    "    random.shuffle(identifiers)\n",
    "    val_size = int(len(identifiers) * val_ratio)\n",
    "    val_identifiers = set(identifiers[:val_size])\n",
    "    train_identifiers = set(identifiers[val_size:])\n",
    "    return train_identifiers, val_identifiers\n",
    "\n",
    "# Split location_reference_point_id\n",
    "train_location_ids, val_location_ids = split_identifiers(location_ids, val_ratio=val_ratio)\n",
    "\n",
    "# Optionally, split vehicle_ids and vehicle_models similarly\n",
    "train_vehicle_ids, val_vehicle_ids = split_identifiers(vehicle_ids)\n",
    "train_vehicle_models, val_vehicle_models = split_identifiers(vehicle_modifications)\n",
    "train_data = {}\n",
    "val_data = {}\n",
    "\n",
    "for testcase_id, testcase in train_dataset.items():\n",
    "    metadata = testcase['metadata']\n",
    "    location_id = metadata['location_reference_point_id']\n",
    "    vehicle_id = metadata['vehicle_id']\n",
    "    vehicle_model = metadata['vehicle_model']\n",
    "    \n",
    "    # Determine whether to include the sample in training or validation set\n",
    "    if (location_id in train_location_ids and\n",
    "        vehicle_id in train_vehicle_ids and\n",
    "        vehicle_model in train_vehicle_models):\n",
    "        train_data[testcase_id] = testcase\n",
    "    else:\n",
    "        val_data[testcase_id] = testcase\n",
    "\n",
    "# Check for overlaps\n",
    "assert not set(train_data.keys()) & set(val_data.keys()), \"Overlap between training and validation sets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, dataset, training=True):\n",
    "        self.data = []\n",
    "        sampling_interval_ns = 4e7  # 0.04 seconds in nanoseconds\n",
    "        initial_state_length = int(5 / 0.04)  # Steps for initial 5 seconds (125 steps)\n",
    "        target_length = int(15 / 0.04)  # Steps from 5s to 20s (375 steps)\n",
    "        sequence_length = initial_state_length + target_length  # Total steps (500 steps)\n",
    "\n",
    "        for testcase_id, testcase in tqdm(dataset.items()):\n",
    "            metadata = testcase['metadata']\n",
    "            vehicle_features = self.encode_vehicle_features(metadata)\n",
    "\n",
    "            # Get control commands\n",
    "            control = testcase['control']\n",
    "            control['acceleration_level'] = control['acceleration_level']\n",
    "            control_seq = control[['stamp_ns', 'acceleration_level', 'steering']].values\n",
    "\n",
    "            # Get localization data\n",
    "            localization = testcase['localization']\n",
    "            localization_seq = localization[['stamp_ns', 'x', 'y', 'z', 'roll', 'pitch', 'yaw']].values\n",
    "    \n",
    "            time_steps = np.arange(0, 60 * 1e9, sampling_interval_ns)\n",
    "            control_resampled = self.resample_sequence(control_seq, time_steps)\n",
    "            control_resampled = control_resampled[:, 1:] # drop ns\n",
    "            localization_resampled = self.resample_sequence(localization_seq, time_steps)\n",
    "            localization_resampled = localization_resampled[:, 1:] # drop ns\n",
    "            \n",
    "            max_start_idx = len(time_steps) - sequence_length\n",
    "            for i in range(0, max_start_idx, initial_state_length):  # Slide window\n",
    "                # Initial localization sequence (first 5 seconds)\n",
    "                \n",
    "                input_localization = deepcopy(localization_resampled[i:i+initial_state_length])  # Shape: [125, 3]\n",
    "                \n",
    "                start_position = deepcopy(input_localization[0][:3])\n",
    "                \n",
    "                input_localization[:, :3] -= start_position # Shift initial localization to zero\n",
    "                \n",
    "                # Target trajectory from t + 5s to t + 20s\n",
    "                output_localization = deepcopy(localization_resampled[i+initial_state_length:i+sequence_length]) # Shape: [375, 3]\n",
    "                output_localization[:, :3] -= start_position\n",
    "            \n",
    "                # Initial and inference control sequence\n",
    "                input_control_sequence = deepcopy(control_resampled[i:i+initial_state_length])\n",
    "                output_control_sequence = deepcopy(control_resampled[i+initial_state_length:i+sequence_length])\n",
    "                \n",
    "            \n",
    "                self.data.append({\n",
    "                    'vehicle_features': vehicle_features,\n",
    "                    'input_localization': input_localization,\n",
    "                    'output_localization': output_localization,\n",
    "                    'input_control_sequence': input_control_sequence,\n",
    "                    'output_control_sequence': output_control_sequence,\n",
    "                })\n",
    "\n",
    "    def encode_vehicle_features(self, metadata):\n",
    "        vehicle_model = vehicle_model_mapping.get(metadata['vehicle_model'], unknown_vehicle_model_idx)\n",
    "        vehicle_modification = vehicle_modification_mapping.get(metadata['vehicle_model_modification'], unknown_vehicle_modification_idx)\n",
    "        tires_front = tires_mapping.get(metadata['tires']['front'], unknown_tires_idx)\n",
    "        tires_rear = tires_mapping.get(metadata['tires']['rear'], unknown_tires_idx)\n",
    "        vehicle_features = [vehicle_model, vehicle_modification, tires_front, tires_rear]\n",
    "        return vehicle_features\n",
    "\n",
    "    def resample_sequence(self, seq, time_steps):\n",
    "        df_seq = pd.DataFrame(seq, columns=['stamp_ns'] + [f'feat_{i}' for i in range(seq.shape[1]-1)])\n",
    "        df_seq = df_seq.set_index('stamp_ns').reindex(time_steps, method='nearest').reset_index()\n",
    "        return df_seq.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tensor_dict = {}\n",
    "        for k, v in sample.items():\n",
    "            if k.startswith('vehicle'):\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.long)\n",
    "            else:\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.float32)\n",
    "        return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24711/24711 [01:59<00:00, 207.61it/s]\n",
      "100%|██████████| 17289/17289 [01:25<00:00, 202.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataset = TrajectoryDataset(dict(itertools.islice(train_data.items(), 10)), training=True)\n",
    "# val_dataset = TrajectoryDataset(dict(itertools.islice(val_data.items(), 10)), training=False)\n",
    "\n",
    "train_dataset = TrajectoryDataset(train_data, training=True)\n",
    "val_dataset = TrajectoryDataset(val_data, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_features: torch.Size([256, 4])\n",
      "input_localization: torch.Size([256, 125, 6])\n",
      "output_localization: torch.Size([256, 375, 6])\n",
      "input_control_sequence: torch.Size([256, 125, 2])\n",
      "output_control_sequence: torch.Size([256, 375, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 32.4544, -17.3852,  -0.8689])\n",
      "tensor([ 32.7172, -17.5265,  -0.8740])\n",
      "tensor([ 32.9784, -17.6699,  -0.8832])\n",
      "tensor([ 33.2404, -17.8106,  -0.8884])\n",
      "tensor([ 33.4974, -17.9514,  -0.8950])\n",
      "tensor([ 33.7579, -18.0924,  -0.9004])\n",
      "tensor([ 34.0197, -18.2343,  -0.9058])\n"
     ]
    }
   ],
   "source": [
    "for ind in [-3, -2, -1]:\n",
    "    print(batch['input_localization'][batch_id][ind][:3])\n",
    "for ind in [0, 1, 2, 3]:\n",
    "    print(batch['output_localization'][batch_id][ind][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryEncoderDecoder(nn.Module):\n",
    "    def __init__(self, vehicle_feature_sizes, embedding_dim, localization_input_size, control_input_size, hidden_size, num_layers):\n",
    "        super(TrajectoryEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Vehicle feature embeddings\n",
    "        self.vehicle_model_embedding = nn.Embedding(num_embeddings=vehicle_feature_sizes['vehicle_model'], embedding_dim=embedding_dim)\n",
    "        self.vehicle_modification_embedding = nn.Embedding(num_embeddings=vehicle_feature_sizes['vehicle_modification'], embedding_dim=embedding_dim)\n",
    "        self.tires_embedding = nn.Embedding(num_embeddings=vehicle_feature_sizes['tires'], embedding_dim=embedding_dim)\n",
    "\n",
    "        # Fully connected layer to combine vehicle features\n",
    "        self.vehicle_fc = nn.Linear(embedding_dim * 4, hidden_size)\n",
    "\n",
    "        # Encoder LSTM for localization\n",
    "        self.localization_encoder = nn.LSTM(input_size=localization_input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Encoder LSTM for control sequence\n",
    "        self.control_encoder = nn.LSTM(input_size=control_input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Decoder LSTM\n",
    "        self.decoder = nn.LSTM(input_size=control_input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(hidden_size, localization_input_size)\n",
    "\n",
    "    def forward(self, vehicle_features, input_localization, input_control_sequence, output_control_sequence):\n",
    "        batch_size = input_localization.size(0)\n",
    "\n",
    "        # Embed vehicle features\n",
    "        vehicle_model = self.vehicle_model_embedding(vehicle_features[:, 0])\n",
    "        vehicle_modification = self.vehicle_modification_embedding(vehicle_features[:, 1])\n",
    "        tires_front = self.tires_embedding(vehicle_features[:, 2])\n",
    "        tires_rear = self.tires_embedding(vehicle_features[:, 3])\n",
    "\n",
    "        # Concatenate vehicle features\n",
    "        vehicle_embedded = torch.cat([vehicle_model, vehicle_modification, tires_front, tires_rear], dim=1)\n",
    "        vehicle_features_encoded = self.vehicle_fc(vehicle_embedded)  # Shape: [batch_size, hidden_size]\n",
    "\n",
    "        # Encoder for localization\n",
    "        _, (hidden_loc, cell_loc) = self.localization_encoder(input_localization)  # hidden_loc: [num_layers, batch_size, hidden_size]\n",
    "\n",
    "        # Encoder for control sequence\n",
    "        _, (hidden_ctrl, cell_ctrl) = self.control_encoder(input_control_sequence)  # hidden_ctrl: [num_layers, batch_size, hidden_size]\n",
    "\n",
    "        # Combine encoder hidden states and vehicle features\n",
    "        # Option to concatenate, sum, or average hidden states\n",
    "        hidden_enc = (hidden_loc + hidden_ctrl) / 2  # Shape: [num_layers, batch_size, hidden_size]\n",
    "        cell_enc = (cell_loc + cell_ctrl) / 2\n",
    "\n",
    "        # Incorporate vehicle features into the hidden state\n",
    "        # We'll add vehicle_features_encoded to the first layer's hidden state\n",
    "        hidden_enc[0] = hidden_enc[0] + vehicle_features_encoded.unsqueeze(0)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_output, _ = self.decoder(output_control_sequence, (hidden_enc, cell_enc))  # decoder_output: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # Output layer\n",
    "        output_localization = self.fc_out(decoder_output)  # Shape: [batch_size, seq_len, localization_input_size]\n",
    "\n",
    "        return output_localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define embedding sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sizes based on your data\n",
    "vehicle_feature_sizes = {\n",
    "    'vehicle_model': len(vehicle_model_mapping),\n",
    "    'vehicle_modification': len(vehicle_modification_mapping),\n",
    "    'tires': len(tires_mapping),\n",
    "}\n",
    "\n",
    "embedding_dim = 16\n",
    "localization_input_size = 6  # For example, x, y, z, roll, pitch, yaw\n",
    "control_input_size = 2  # acceleration_level, steering\n",
    "hidden_size = 128\n",
    "num_layers = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 375, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['output_localization'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z, roll, pith, yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEGMENT_LENGTH = 1.0\n",
    "\n",
    "def calculate_metric_on_batch(output_np, target_np, segment_length=1.0):\n",
    "    \"\"\"\n",
    "    output_np: numpy array of shape [batch_size, seq_len, 4], predicted x, y, yaw\n",
    "    target_np: numpy array of same shape, ground truth x, y, yaw\n",
    "\n",
    "    Returns:\n",
    "        metric: float, the average metric over the batch\n",
    "    \"\"\"\n",
    "    x_pred, y_pred, yaw_pred = output_np[..., 0], output_np[..., 1], output_np[..., 2]\n",
    "    x_gt, y_gt, yaw_gt = target_np[..., 0], target_np[..., 1], target_np[..., 2]\n",
    "\n",
    "    # Compute c1 and c2 for predicted\n",
    "    c1_pred = np.stack([x_pred, y_pred], axis=-1)\n",
    "    c2_pred = c1_pred + segment_length * np.stack([np.cos(yaw_pred), np.sin(yaw_pred)], axis=-1)\n",
    "\n",
    "    # Compute c1 and c2 for ground truth\n",
    "    c1_gt = np.stack([x_gt, y_gt], axis=-1)\n",
    "    c2_gt = c1_gt + segment_length * np.stack([np.cos(yaw_gt), np.sin(yaw_gt)], axis=-1)\n",
    "\n",
    "    # Compute distances between corresponding points\n",
    "    dist_c1 = np.linalg.norm(c1_pred - c1_gt, axis=-1)\n",
    "    dist_c2 = np.linalg.norm(c2_pred - c2_gt, axis=-1)\n",
    "\n",
    "    # Compute pose metric\n",
    "    pose_metric = np.sqrt((dist_c1 ** 2 + dist_c2 ** 2) / 2.0)\n",
    "    metric = np.mean(pose_metric)\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TrajectoryEncoderDecoder(\n",
    "    vehicle_feature_sizes=vehicle_feature_sizes,\n",
    "    embedding_dim=embedding_dim,\n",
    "    localization_input_size=localization_input_size,\n",
    "    control_input_size=control_input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrajectoryEncoderDecoder(\n",
       "  (vehicle_model_embedding): Embedding(2, 16)\n",
       "  (vehicle_modification_embedding): Embedding(6, 16)\n",
       "  (tires_embedding): Embedding(14, 16)\n",
       "  (vehicle_fc): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (localization_encoder): LSTM(6, 128, num_layers=2, batch_first=True)\n",
       "  (control_encoder): LSTM(2, 128, num_layers=2, batch_first=True)\n",
       "  (decoder): LSTM(2, 128, num_layers=2, batch_first=True)\n",
       "  (fc_out): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 125, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_localization'][..., [0,1,-1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-26.2203,  33.3108,   2.2151])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_localization'][..., [0,1,-1]][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6220e+01,  3.3311e+01, -4.0256e-01,  3.5852e-02, -2.1367e-02,\n",
       "         2.2151e+00])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_localization'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:53<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 157.1310, Metric: 18.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:23<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 181.5270, Metric: 20.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:53<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 98.3395, Metric: 14.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:22<00:00, 23.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 140.6011, Metric: 18.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:53<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 69.2934, Metric: 12.3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:25<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 110.1188, Metric: 15.8064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:53<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 61.5115, Metric: 11.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:22<00:00, 23.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 98.0629, Metric: 15.1598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:53<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 40.1784, Metric: 9.5405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:22<00:00, 23.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 85.1788, Metric: 13.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:55<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 29.6990, Metric: 8.0911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:22<00:00, 23.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 79.0974, Metric: 13.3542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:53<00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 23.4913, Metric: 7.1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:22<00:00, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 70.6778, Metric: 12.4278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [00:53<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training Loss: 20.9658, Metric: 6.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:22<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 68.5420, Metric: 12.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 463/773 [00:31<00:21, 14.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m epoch_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m      9\u001b[0m     vehicle_features \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicle_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m     input_localization \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_localization\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[23], line 82\u001b[0m, in \u001b[0;36mTrajectoryDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     80\u001b[0m         tensor_dict[k] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(v, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m         tensor_dict[k] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_dict\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_metric = 0\n",
    "    for sample in tqdm(train_loader):\n",
    "        vehicle_features = sample['vehicle_features'].to(device)\n",
    "        input_localization = sample['input_localization'].to(device)\n",
    "        output_localization = sample['output_localization'].to(device)\n",
    "        input_control_sequence = sample['input_control_sequence'].to(device)\n",
    "        output_control_sequence = sample['output_control_sequence'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output_localization = model(\n",
    "            vehicle_features,\n",
    "            input_localization,\n",
    "            input_control_sequence,\n",
    "            output_control_sequence\n",
    "        )\n",
    "        loss = criterion(predicted_output_localization, output_localization)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        predicted_x_y_yaw = predicted_output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "        gt_x_y_yaw = output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "        batch_metric = calculate_metric_on_batch(predicted_x_y_yaw, gt_x_y_yaw)\n",
    "        epoch_metric += batch_metric\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    avg_metric = epoch_metric / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_loss:.4f}, Metric: {avg_metric:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_metric = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(val_loader):\n",
    "            vehicle_features = sample['vehicle_features'].to(device)\n",
    "            input_localization = sample['input_localization'].to(device)\n",
    "            output_localization = sample['output_localization'].to(device)\n",
    "            input_control_sequence = sample['input_control_sequence'].to(device)\n",
    "            output_control_sequence = sample['output_control_sequence'].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            predicted_output_localization = model(\n",
    "                vehicle_features,\n",
    "                input_localization,\n",
    "                input_control_sequence,\n",
    "                output_control_sequence\n",
    "            )\n",
    "            loss = criterion(predicted_output_localization, output_localization)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_x_y_yaw = predicted_output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "            gt_x_y_yaw = output_localization[..., [0,1,-1]].detach().cpu().numpy()\n",
    "            batch_metric = calculate_metric_on_batch(predicted_x_y_yaw, gt_x_y_yaw)\n",
    "            val_metric += batch_metric\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_metric = val_metric / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Metric: {avg_val_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataset_path):\n",
    "        self.data = []\n",
    "        sampling_interval_ns = 4e7  # 0.04 seconds in nanoseconds\n",
    "        initial_state_length = int(5 / 0.04)  # 125 steps\n",
    "        target_length = int(15 / 0.04)        # 375 steps\n",
    "        sequence_length = initial_state_length + target_length  # 500 steps\n",
    "\n",
    "        # Get list of test case IDs (folder names)\n",
    "        testcase_ids = sorted([name for name in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, name))])\n",
    "\n",
    "        for testcase_id in tqdm(testcase_ids):\n",
    "            testcase_path = os.path.join(dataset_path, testcase_id)\n",
    "\n",
    "            # Load metadata and encode vehicle features\n",
    "            with open(os.path.join(testcase_path, 'metadata.json'), 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            vehicle_features = self.encode_vehicle_features(metadata)\n",
    "\n",
    "            # Load localization data (first 5 seconds)\n",
    "            localization = pd.read_csv(os.path.join(testcase_path, 'localization.csv'))\n",
    "            localization_seq = localization[['stamp_ns', 'x', 'y', 'z', 'roll', 'pitch', 'yaw']].values\n",
    "\n",
    "            # Load control data (first 20 seconds)\n",
    "            control = pd.read_csv(os.path.join(testcase_path, 'control.csv'))\n",
    "            control['acceleration_level'] = control['acceleration_level'].fillna(0)\n",
    "            control_seq = control[['stamp_ns', 'acceleration_level', 'steering']].values\n",
    "\n",
    "            # Load requested stamps\n",
    "            requested_stamps = pd.read_csv(os.path.join(testcase_path, 'requested_stamps.csv'))['stamp_ns'].values\n",
    "\n",
    "            # Resample sequences to fixed time steps\n",
    "            time_steps_localization = np.arange(0, 5 * 1e9, sampling_interval_ns)\n",
    "            time_steps_control = np.arange(0, 20 * 1e9, sampling_interval_ns)\n",
    "\n",
    "            localization_resampled = self.resample_sequence(localization_seq, time_steps_localization)\n",
    "            control_resampled = self.resample_sequence(control_seq, time_steps_control)\n",
    "\n",
    "            # Process localization data\n",
    "            localization_resampled = localization_resampled[:, 1:]  # Drop stamp_ns\n",
    "            input_localization = localization_resampled.copy()      # Shape: [125, 7]\n",
    "\n",
    "            # Subtract start position\n",
    "            start_position = input_localization[0, :3].copy()\n",
    "            input_localization[:, :3] -= start_position\n",
    "\n",
    "            # Prepare input_control_sequence (first 5 seconds)\n",
    "            control_resampled = control_resampled[:, 1:]  # Drop stamp_ns\n",
    "            input_control_sequence = control_resampled[:initial_state_length].copy()  # [125, 2]\n",
    "\n",
    "            # Prepare output_control_sequence (from 5s to 20s)\n",
    "            output_control_sequence = control_resampled[initial_state_length:].copy()  # [375, 2]\n",
    "\n",
    "            self.data.append({\n",
    "                'testcase_id': int(testcase_id),\n",
    "                'vehicle_features': vehicle_features,\n",
    "                'input_localization': input_localization,\n",
    "                'input_control_sequence': input_control_sequence,\n",
    "                'output_control_sequence': output_control_sequence,\n",
    "                'start_position': start_position,\n",
    "                'requested_stamps': requested_stamps\n",
    "            })\n",
    "\n",
    "    def encode_vehicle_features(self, metadata):\n",
    "        vehicle_model = vehicle_model_mapping.get(metadata['vehicle_model'], unknown_vehicle_model_idx)\n",
    "        vehicle_modification = vehicle_modification_mapping.get(metadata['vehicle_model_modification'], unknown_vehicle_modification_idx)\n",
    "        tires_front = tires_mapping.get(metadata['tires']['front'], unknown_tires_idx)\n",
    "        tires_rear = tires_mapping.get(metadata['tires']['rear'], unknown_tires_idx)\n",
    "        vehicle_features = [vehicle_model, vehicle_modification, tires_front, tires_rear]\n",
    "        return vehicle_features\n",
    "\n",
    "    def resample_sequence(self, seq, time_steps):\n",
    "        df_seq = pd.DataFrame(seq, columns=['stamp_ns'] + [f'feat_{i}' for i in range(seq.shape[1]-1)])\n",
    "        df_seq = df_seq.set_index('stamp_ns').reindex(time_steps, method='nearest').reset_index()\n",
    "        return df_seq.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tensor_dict = {}\n",
    "        for k, v in sample.items():\n",
    "            if k == 'vehicle_features':\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.long)\n",
    "            elif k in ['input_localization', 'input_control_sequence', 'output_control_sequence']:\n",
    "                tensor_dict[k] = torch.tensor(v, dtype=torch.float32)\n",
    "            else:\n",
    "                tensor_dict[k] = v  # Keep as is (e.g., start_position, requested_stamps, testcase_id)\n",
    "        return tensor_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [01:02<00:00, 127.82it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(TEST_DATASET_PATH)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader):\n\u001b[1;32m      6\u001b[0m     testcase_id \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestcase_id\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m     vehicle_features \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvehicle_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     input_localization \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_localization\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     input_control_sequence \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_control_sequence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(test_loader):\n",
    "        testcase_id = sample['testcase_id'][0]\n",
    "        vehicle_features = sample['vehicle_features'].to(device)\n",
    "        input_localization = sample['input_localization'].to(device)\n",
    "        input_control_sequence = sample['input_control_sequence'].to(device)\n",
    "        output_control_sequence = sample['output_control_sequence'].to(device)\n",
    "        start_position = sample['start_position'][0].numpy()\n",
    "        requested_stamps = sample['requested_stamps'][0].numpy()\n",
    "\n",
    "        # Check sequence lengths\n",
    "        if input_localization.size(1) != initial_state_length:\n",
    "            print(f\"Skipping {testcase_id}: input_localization length mismatch\")\n",
    "            continue\n",
    "        if input_control_sequence.size(1) != initial_state_length:\n",
    "            print(f\"Skipping {testcase_id}: input_control_sequence length mismatch\")\n",
    "            continue\n",
    "        if output_control_sequence.size(1) != target_length:\n",
    "            print(f\"Skipping {testcase_id}: output_control_sequence length mismatch\")\n",
    "            continue\n",
    "\n",
    "        # Forward pass\n",
    "        try:\n",
    "            predicted_output_localization = model(\n",
    "                vehicle_features,\n",
    "                input_localization,\n",
    "                input_control_sequence,\n",
    "                output_control_sequence\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {testcase_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        # Get x, y positions, yaw\n",
    "        yaw_pred = predicted_output_localization[:, -1]\n",
    "        x_pred = predicted_output_localization[:, 0]\n",
    "        y_pred = predicted_output_localization[:, 1]\n",
    "\n",
    "        # Time steps corresponding to output predictions (from 5s to 20s every 0.04s)\n",
    "        time_steps = np.arange(5 * 1e9, 20 * 1e9, 4e7)  # [375]\n",
    "\n",
    "        # Map requested_stamps to indices in time_steps\n",
    "        indices = np.searchsorted(time_steps, requested_stamps)\n",
    "\n",
    "        # Handle any indices out of bounds\n",
    "        indices = np.clip(indices, 0, len(time_steps) - 1)\n",
    "\n",
    "        # Extract predictions at requested timestamps\n",
    "        x_pred = x_pred[indices]\n",
    "        y_pred = y_pred[indices]\n",
    "        yaw_pred = yaw_pred[indices]\n",
    "\n",
    "        # Collect predictions\n",
    "        for stamp_ns, x, y, yaw in zip(requested_stamps, x_pred, y_pred, yaw_pred):\n",
    "            predictions.append({\n",
    "                'testcase_id': testcase_id,\n",
    "                'stamp_ns': int(stamp_ns),\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'yaw': yaw\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 5)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.explode(column=['stamp_ns', 'x', 'y', 'yaw']).to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NSECS_IN_SEC = 1000000000\n",
    "\n",
    "def secs_to_nsecs(secs: float):\n",
    "    return int(secs * NSECS_IN_SEC)\n",
    "\n",
    "def nsecs_to_secs(nsecs: int):\n",
    "    return float(nsecs) / NSECS_IN_SEC\n",
    "\n",
    "def yaw_direction(yaw_value):\n",
    "    return np.array([np.cos(yaw_value), np.sin(yaw_value)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple pose prediction logic without taking into account control states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_df_to_poses(loc_df):\n",
    "    poses = []\n",
    "    for stamp_ns, x, y, yaw in zip(loc_df['stamp_ns'], loc_df['x'], loc_df['y'], loc_df['yaw']):\n",
    "        poses.append({'stamp_ns': stamp_ns, 'pos': np.array([x, y]), 'yaw': yaw})\n",
    "    return poses\n",
    "\n",
    "# naive estimation of speed at last known localization pose\n",
    "def dummy_estimate_last_speed(localization_poses):\n",
    "    last_pose = localization_poses[-1]\n",
    "    \n",
    "    start_pose_idx = -1\n",
    "    for i, pose in enumerate(localization_poses, start=1-len(localization_poses)):\n",
    "        start_pose_idx = i\n",
    "        if nsecs_to_secs(last_pose['stamp_ns']) - nsecs_to_secs(pose['stamp_ns']) > 1.: # sec\n",
    "            break\n",
    "            \n",
    "    start_pose = localization_poses[start_pose_idx]\n",
    "    dt_sec = nsecs_to_secs(last_pose['stamp_ns']) - nsecs_to_secs(start_pose['stamp_ns'])\n",
    "    \n",
    "    if dt_sec > 1e-5:\n",
    "        return np.linalg.norm(last_pose['pos'][:2] - start_pose['pos'][:2]) / dt_sec\n",
    "    return 5. # some default value\n",
    "\n",
    "def dummpy_predict_pose(last_loc_pose: dict, last_speed: float, prediction_stamp: int):\n",
    "    dt_sec = nsecs_to_secs(prediction_stamp) - nsecs_to_secs(last_loc_pose['stamp_ns'])\n",
    "    distance = dt_sec * last_speed\n",
    "    direction = yaw_direction(last_loc_pose['yaw'])\n",
    "    pos_translate = direction * distance\n",
    "    return {\"pos\": last_loc_pose['pos'] + pos_translate, 'yaw': last_loc_pose['yaw']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_testcase(testcase: dict):\n",
    "    loc_df = testcase['localization']\n",
    "    localization_poses = localization_df_to_poses(loc_df)\n",
    "    \n",
    "    last_loc_pose = localization_poses[-1]\n",
    "    last_speed = dummy_estimate_last_speed(localization_poses)\n",
    "    \n",
    "    predicted_poses = []\n",
    "    for stamp in testcase['requested_stamps']['stamp_ns']:\n",
    "        pose = dummpy_predict_pose(last_loc_pose, last_speed, stamp)\n",
    "        predicted_poses.append(pose)\n",
    "        \n",
    "    predictions = {}\n",
    "    predictions['stamp_ns'] = testcase['requested_stamps']['stamp_ns']\n",
    "    predictions['x'] = [pose['pos'][0] for pose in predicted_poses]\n",
    "    predictions['y'] = [pose['pos'][1] for pose in predicted_poses]\n",
    "    predictions['yaw'] = [pose['yaw'] for pose in predicted_poses]\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "def predict_test_dataset(test_dataset: dict):\n",
    "    predictions = {}\n",
    "    for testcase_id, testcase in tqdm(test_dataset.items()): \n",
    "        predictions[testcase_id] = predict_testcase(testcase)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make prediction for requested stamps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:23<00:00, 343.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = predict_test_dataset(test_dataset)\n",
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(dataset_predictions: dict, prediction_file_path: str):\n",
    "    prediction_list = []\n",
    "    for testcase_id, prediction in tqdm(dataset_predictions.items()):\n",
    "        prediction['testcase_id'] = [testcase_id] * len(prediction)\n",
    "        prediction_list.append(prediction)\n",
    "    predictions_df = pd.concat(prediction_list)\n",
    "    predictions_df = predictions_df.reindex(columns=[\"testcase_id\", \"stamp_ns\", \"x\", \"y\", \"yaw\"])\n",
    "    print(len(predictions_df))\n",
    "    predictions_df.to_csv(prediction_file_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:01<00:00, 4018.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998763\n"
     ]
    }
   ],
   "source": [
    "write_predictions(test_predictions, os.path.join(ROOT_DATA_FOLDER, \"dummy_prediction.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./YandexCup2024v2'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_prediction = pd.read_csv('./YandexCup2024v2/dummy_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testcase_id</th>\n",
       "      <th>stamp_ns</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5000888836</td>\n",
       "      <td>-1490.905035</td>\n",
       "      <td>-1310.813635</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5040043013</td>\n",
       "      <td>-1490.955001</td>\n",
       "      <td>-1310.716927</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5079989560</td>\n",
       "      <td>-1491.005979</td>\n",
       "      <td>-1310.618261</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5120797471</td>\n",
       "      <td>-1491.058057</td>\n",
       "      <td>-1310.517468</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5165218288</td>\n",
       "      <td>-1491.114744</td>\n",
       "      <td>-1310.407751</td>\n",
       "      <td>2.047693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   testcase_id    stamp_ns            x            y       yaw\n",
       "0            0  5000888836 -1490.905035 -1310.813635  2.047693\n",
       "1            0  5040043013 -1490.955001 -1310.716927  2.047693\n",
       "2            0  5079989560 -1491.005979 -1310.618261  2.047693\n",
       "3            0  5120797471 -1491.058057 -1310.517468  2.047693\n",
       "4            0  5165218288 -1491.114744 -1310.407751  2.047693"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2998763, 5)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_prediction.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe final metric. As a first step, all predicted triples $(x,y,yaw)$ are being converted into 2 points $[(x_1, y_1), (x_2, y_2)]$ in the following way:\n",
    "$$\n",
    "(x_1, y_1) = (x, y), \\\\\n",
    "(x_2, y_2) = (x_1, y_1) + S \\times (yaw_x, yaw_y)\n",
    "$$  \n",
    "\n",
    "where $S = 1$. In other words, we build a directed segment of length $1$. These points then used in the metric calculation.\n",
    "\n",
    "\n",
    "Metric for a single pose (rmse):\n",
    "\n",
    "$$\n",
    "pose\\_metric = \\sqrt{ \\frac{\\displaystyle\\sum_{j=1}^{k} {(x_j-\\hat{x_j})^2 + (y_j-\\hat{y_j})^2}}{k} }\n",
    "$$\n",
    "\n",
    "where $k$ - number of points that describe single pose (in our case $k=2$).\n",
    "\n",
    "Metric for a testcase:\n",
    "\n",
    "$$\n",
    "testcase\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}pose\\_metric_i\n",
    "$$\n",
    "\n",
    "where $n$ - number of localization points to predict.\n",
    "\n",
    "And, final metric for a whole dataset:\n",
    "\n",
    "$$\n",
    "dataset\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}testcase\\_metric_i\n",
    "$$\n",
    "\n",
    "where $n$ - number of test cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementation of the metric calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEGMENT_LENGTH = 1.\n",
    "\n",
    "def yaw_direction(yaw_value):\n",
    "    return np.array([np.cos(yaw_value), np.sin(yaw_value)])\n",
    "\n",
    "def build_car_points(x_y_yaw):\n",
    "    directions = np.vstack(yaw_direction(x_y_yaw[:, -1]))\n",
    "    \n",
    "    front_points = x_y_yaw[:, :-1] + SEGMENT_LENGTH * directions.T\n",
    "    points = np.vstack([x_y_yaw[:, :-1], front_points])\n",
    "    return points\n",
    "\n",
    "def build_car_points_from_merged_df(df: pd.DataFrame):\n",
    "    points_gt = df[['x_gt', 'y_gt', 'yaw_gt']].to_numpy()\n",
    "    points_pred = df[['x_pred', 'y_pred', 'yaw_pred']].to_numpy()\n",
    "    \n",
    "    points_gt = build_car_points(points_gt)\n",
    "    points_pred = build_car_points(points_pred)\n",
    "    return points_gt, points_pred\n",
    "\n",
    "def calculate_metric_testcase(df: pd.DataFrame):        \n",
    "    points_gt, points_pred = build_car_points_from_merged_df(df)\n",
    "    \n",
    "    metric = np.mean(np.sqrt(2. * np.mean((points_gt - points_pred) ** 2, axis=1)))\n",
    "    return metric\n",
    "\n",
    "def calculate_metric_dataset(ground_truth_df: pd.DataFrame, prediction_df: pd.DataFrame):\n",
    "    assert (len(ground_truth_df) == len(prediction_df))\n",
    "    \n",
    "    df = ground_truth_df.merge(prediction_df, on=['testcase_id', 'stamp_ns'], suffixes=['_gt', '_pred'])\n",
    "    \n",
    "    metric = df.groupby('testcase_id').apply(calculate_metric_testcase)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
